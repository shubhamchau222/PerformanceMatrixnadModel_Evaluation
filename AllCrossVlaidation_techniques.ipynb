{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **```All types of Cross  validation technique```**\n",
    "\n",
    "\n",
    "        - In this file i've Discussed about the cross-validation techniques and the Selection of the proper Scoring Param's.   \n",
    "        \n",
    "        - Cross validation is important step in machine projects \n",
    "        - It gives the clear idea about the model Performance \n",
    "        - also prevent the Overfitting Condition \n",
    "        - the selection of scoring Parameter in CV is Important step and it's depends on the Use-cases\n",
    "        - if the range between Highest and Lowest Score is high , then it's clear sign of poor model performance \n",
    "            hence we need to do Hyper-parameter tuning of model again and again until we get proper result..\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV , KFold ,train_test_split , cross_val_score , StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score  , auc  , roc_auc_score\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'data.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "data = data.dropna(axis=1)\n",
    "X = data.drop(['diagnosis']  ,axis=1)\n",
    "X = X.drop(['id'] , axis=1)\n",
    "y = data['diagnosis']\n",
    "y = y.map({'M':0,\"B\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HoldOut_ValidationApproch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "''' It's simple train test split dataset , divides dataset in two part(train & test )\n",
    "        - data selected randomly , as we change the Random_state model Accuracy will change it's the \n",
    "        major drawback of this approch..\n",
    "''' \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9181286549707602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y , test_size=0.3 , random_state=12)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train , y_train)\n",
    "result = clf.score(X_test , y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold  cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold , cross_val_score\n",
    "import numpy as np \n",
    "model = DecisionTreeClassifier()\n",
    "k_foldValidation = KFold(n_splits=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94736842 0.9122807  0.87719298 0.96491228 0.9122807  0.98245614\n",
      " 0.9122807  0.98245614 0.96491228 0.92857143]\n",
      "\n",
      "  0.9384711779448622\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator=model , X=X , y=y , cv= k_foldValidation )\n",
    "print(results)\n",
    "print(\"\\n \" , np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python \n",
    "'''\n",
    "        - helps to overcome the Overfitting , gives the clear idea about the model Performance \n",
    "        - If the Range between highest score and lowest score is high , then it'll the sign of overfitting , \n",
    "            we need todo hyper-prameter tunning again \n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-fold Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92982456 0.85964912 0.92982456 0.89473684 0.98245614 0.89473684\n",
      " 0.89473684 0.94736842 0.92982456 0.96428571]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold \n",
    "skfold = StratifiedKFold(n_splits=10)\n",
    "model  =  DecisionTreeClassifier()\n",
    "result = cross_val_score(estimator=model ,X = X , y=y , cv=skfold )\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9227443609022556\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python \n",
    "'''\n",
    "        - helps to overcome the Overfitting , gives the clear idea about the model Performance \n",
    "        -  if dataset is unbalanced , then we use stratified K-fold validation for the model validation , \n",
    "        \n",
    "        - StratifiedKFold , ensures that the equal proportion of element should be choosen from each class  while cross-validation \n",
    "        \n",
    "        - If the Range between highest score and lowest score is high , then it'll the sign of overfitting , \n",
    "            we need todo hyper-prameter tunning again \n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "model = DecisionTreeClassifier()\n",
    "le_cv = LeaveOneOut()\n",
    "result = cross_val_score(estimator = model, X = X , y=y, cv=le_cv) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python \n",
    "# result \n",
    "'''\n",
    "        This cv techniques ,selects the one data element for test , remaining data elements are considered as Train data for \n",
    "        iteration..\n",
    "        - the execution time is depends on the size of the dataset \n",
    "        - Not useful for huge dataset \n",
    "        - takes more time to run\n",
    "'''\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selection of proper Scoring Parameter During Cross-Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ScoringPAGE DOCUMENT Visit here](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "\n",
    "Scoring_Parameters : https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "when to use which matrics : https://medium.com/analytics-vidhya/precision-recall-tradeoff-for-real-world-use-cases-c6de4fabbcd0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python \n",
    "'''\n",
    "        The selection of the Scoring Parameter is completely depends on the Problem Statements , \n",
    "        for example : in medical domain , we use to reduce the Flase-Negatives , we demnad on the recall(sensitivity) mostly ,      \n",
    "'''\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **when precision** isimportant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91428571 0.88571429 0.92105263 0.91891892 0.94594595 0.91666667\n",
      " 0.89189189 0.97142857 1.         0.96969697]\n"
     ]
    }
   ],
   "source": [
    "skfold = StratifiedKFold(n_splits=10)\n",
    "model  =  DecisionTreeClassifier()\n",
    "result = cross_val_score(estimator=model ,X = X , y=y , cv=skfold , scoring=('precision'))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9335601596127912"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### when we are focusing more on recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94285714 0.91428571 0.97222222 0.88888889 0.97222222 0.91666667\n",
      " 0.97222222 0.94444444 0.86111111 0.94285714]\n"
     ]
    }
   ],
   "source": [
    "# select the Scoring Parameter as per usecase ((problem statement))\n",
    "# for more details visit below\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=10)\n",
    "model  =  DecisionTreeClassifier()\n",
    "result = cross_val_score(estimator=model ,X = X , y=y , cv=skfold , scoring=('recall'))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9327777777777777"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For considering the multiple matrixes use sklearn.model_selction.cross_validate ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "model= DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02498484, 0.01898694, 0.02398539, 0.01524305, 0.01499057,\n",
       "        0.01498914, 0.01398993, 0.02798748, 0.05796123, 0.05296826]),\n",
       " 'score_time': array([0.01099396, 0.0089941 , 0.0089972 , 0.00774074, 0.00599813,\n",
       "        0.00599766, 0.0059979 , 0.02098298, 0.02598405, 0.02098155]),\n",
       " 'test_recall': array([0.94285714, 0.88571429, 0.94444444, 0.91666667, 0.97222222,\n",
       "        0.88888889, 0.97222222, 0.94444444, 0.88888889, 0.88571429]),\n",
       " 'test_precision': array([0.94285714, 0.86111111, 0.91891892, 0.91666667, 1.        ,\n",
       "        0.91428571, 0.85365854, 0.97142857, 1.        , 1.        ])}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(estimator=model , X=X , y=y  ,cv = 10 ,  scoring=('recall', 'precision'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "'''\n",
    "    -  Precision measures that out of all the positive predicted examples, how many detections were correct?\n",
    "    -  Recall measures that out of all actual positive examples, how many were we able to identify?\n",
    "    \n",
    "    \n",
    "    - secret keys \n",
    "            1. When you cannot afford to have any false negatives, you prioritize recall.(sensitivity)\n",
    "            2. When you cannot afford to have any false positives, you prioritize precision.          \n",
    "\n",
    "'''\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python \n",
    "'''\n",
    "            Letâ€™s dive right into what we have been waiting for â€” the different use-cases \n",
    "                    where we prioritize one metric over the other.\n",
    "                    \n",
    "            1) Medical test (eg. cancer detection):  Recall is more important\n",
    "                   \n",
    "                        ðŸ”– It is okay to classify a healthy person as having cancer (false positive) \n",
    "                        and following up with more medical tests, \n",
    "                        but it is definitely not okay to miss identifying a cancer patient or \n",
    "                        classifying a cancer patient as healthy (false negative) since the personâ€™s\n",
    "                        life is at stake.\n",
    "                        \n",
    "            2) Recommendation Systems: Precision is more important\n",
    "                        ðŸ”– Missing out to recommend a particular famous movie is okay (low recall), \n",
    "                        but the overall recommendations should be good. If the customer is shown a lot\n",
    "                        of irrelevant results (false positives), it will be a very bad experience for the user.\n",
    "                        \n",
    "            3)  Predicting a good day based on weather conditions to launch satellite: Precision is more important\n",
    "                        ðŸ”– Missing out to predict a good weather day is okay (low recall),\n",
    "                        but predicting the wrong weather day (false positive) to launch the \n",
    "                        satellite can be disastrous.\n",
    "                        \n",
    "            4)  Criminal death punishment: Precision is more important\n",
    "                        ðŸ”– Missing out to punish a criminal is okay (low recall), \n",
    "                        but incriminating an innocent person (false positive) is undesirable.\n",
    "                        \n",
    "            5)  Email spam detection: Precision is more important\n",
    "                        ðŸ”– Missing out to detect/classify a spam email is okay (low recall),\n",
    "                        but no legit or important email must go into the spam folder (false positive).\n",
    "            \n",
    "            6) Identifying good customers for a bank loan: Precision is more \n",
    "                        ðŸ”– Missing out to identify/classify a good customer eligible for the loan is okay (low recall), \n",
    "                        but approving a loan to a bad customer (false positive) who may never repay it is undesirable.\n",
    "                        \n",
    "            7) Flagging fraudulent transactions: Recall is more important\n",
    "                        ðŸ”– It is okay to classify a legit transaction as fraudulent â€” \n",
    "                        it can always be reverified by passing through additional checks.\n",
    "                        But it is definitely not okay to classify a fraudulent transaction\n",
    "                        as legit (false negative).\n",
    "            \n",
    "\n",
    "\n",
    "'''\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
